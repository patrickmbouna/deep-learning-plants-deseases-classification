{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "AlexNet Plant Disease Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrickmbouna/deep-learning-plants-deseases-classification/blob/main/AlexNet_Plant_Disease_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BLM6UPLQ_um"
      },
      "source": [
        "# **Plant Disease Classification**\n",
        "\n",
        "---\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1200/1*FswlF4lZPQ4kT_gkybacZw.jpeg)\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "Getting affected by a disease is very common in plants due to various factors such as fertilizers, cultural practices followed, environmental conditions, etc. These diseases hurt agricultural yield and eventually the economy based on it.Â \n",
        "\n",
        "Any technique or method to overcome this problem and getting a warning before the plants are infected would aid farmers to efficiently cultivate crops or plants, both qualitatively and quantitatively. Thus, disease detection in plants plays a very important role in agriculture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3YjEHM-HQpg"
      },
      "source": [
        "# Download Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-nTknvLSCIH"
      },
      "source": [
        "First, we download the `PlantVillage` dataset from Google Drive by using the unique `id` it holds and unzip the downloaded **PlantVillage.zip** into the **PlantVillage** dataset folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4MljCl78SnG",
        "outputId": "f54146f3-aecb-49b2-bac9-43ea705eb98d"
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "file_id = '18DbC6Xj4NP-hLzI14WuMaAEyq482vNfn'\n",
        "\n",
        "# Download dataset\n",
        "!gdown https://drive.google.com/uc?id={file_id}\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip -q PlantVillage.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18DbC6Xj4NP-hLzI14WuMaAEyq482vNfn\n",
            "To: /content/PlantVillage.zip\n",
            "866MB [00:08, 99.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA5gRqs6y97j"
      },
      "source": [
        "# Import Libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUGtqDPgSmZJ"
      },
      "source": [
        "Importing necessary libraries and modules required to build the classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMUpYwh1HpCi"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1JRNVU0S_eq"
      },
      "source": [
        "# Building CNN based on AlexNet Architecture\n",
        "\n",
        "# Importing Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFPjNCDiNF4f"
      },
      "source": [
        "import json\n",
        "import time\n",
        "\n",
        "import joblib\n",
        "import keras\n",
        "import tensorflow\n",
        "from keras.engine.saving import load_model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers import Input, GlobalAveragePooling2D, concatenate, AveragePooling2D\n",
        "from keras import models\n",
        "from keras.models import Model\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "import matplotlib.pyplot as plt\n",
        "#from keras.callbacks import tensorboard_v1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNmahsdcHM_D"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Chojawz3jw"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyRk7kzTzOpO"
      },
      "source": [
        "Initializing a few parameters required for the image dataset preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5eHthEdIBsr"
      },
      "source": [
        "# Dimension of resized image\n",
        "DEFAULT_IMAGE_SIZE = tuple((224, 224))\n",
        "\n",
        "# Number of images used to train the model\n",
        "N_IMAGES = 100\n",
        "\n",
        "# Path to the dataset folder\n",
        "root_dir = './PlantVillage'\n",
        "\n",
        "train_dir = os.path.join(root_dir, 'train')\n",
        "val_dir = os.path.join(root_dir, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljEtGO92TgX7",
        "outputId": "9ce20829-24dd-4a30-c663-cd5c31bd384d"
      },
      "source": [
        "# Initializing the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Convolution Step 1\n",
        "classifier.add(Convolution2D(96, 11, strides = (4, 4), padding = 'valid', input_shape=(224, 224, 3), activation = 'relu'))\n",
        "\n",
        "# Max Pooling Step 1\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# Convolution Step 2\n",
        "classifier.add(Convolution2D(256, 11, strides = (1, 1), padding='valid', activation = 'relu'))\n",
        "\n",
        "# Max Pooling Step 2\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding='valid'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# Convolution Step 3\n",
        "classifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# Convolution Step 4\n",
        "classifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# Convolution Step 5\n",
        "classifier.add(Convolution2D(256, 3, strides=(1,1), padding='valid', activation = 'relu'))\n",
        "\n",
        "# Max Pooling Step 3\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# Flattening Step\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Full Connection Step\n",
        "classifier.add(Dense(units = 4096, activation = 'relu'))\n",
        "classifier.add(Dropout(0.4))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(Dense(units = 4096, activation = 'relu'))\n",
        "classifier.add(Dropout(0.4))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(Dense(units = 1000, activation = 'relu'))\n",
        "classifier.add(Dropout(0.2))\n",
        "classifier.add(BatchNormalization())\n",
        "classifier.add(Dense(units = 39, activation = 'softmax'))\n",
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 27, 27, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 17, 17, 256)       2973952   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 39)                39039     \n",
            "=================================================================\n",
            "Total params: 28,118,791\n",
            "Trainable params: 28,097,655\n",
            "Non-trainable params: 21,136\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzQsQs6fTUGU"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Compiling the CNN\n",
        "# classifier.compile(optimizer='adam',\n",
        "#                    loss='categorical_crossentropy',\n",
        "#                    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Compiling the CNN\n",
        "\n",
        "classifier.compile(optimizer=optimizers.SGD(lr=0.001, momentum=0.9, decay=0.005),\n",
        "                   loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VniEgrpT-Zb"
      },
      "source": [
        "\n",
        "# image preprocessing\n",
        "#train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "#                                   shear_range=0.2,\n",
        "#                                   zoom_range=0.2,\n",
        "#                                   width_shift_range=0.2,\n",
        "#                                   height_shift_range=0.2,\n",
        "#                                   rotation_range=40,\n",
        "#                                   horizontal_flip=True,\n",
        "#                                   fill_mode='nearest')\n",
        "\n",
        "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data_dir = train_dir   # directory of training data\n",
        "\n",
        "test_data_dir = val_dir      # directory of test data\n",
        "\n",
        "#training_set = train_datagen.flow_from_directory(train_data_dir,\n",
        "#                                                 target_size=(224, 224),\n",
        "#                                                 batch_size=batch_size,\n",
        "#                                                 class_mode='categorical')\n",
        "\n",
        "#test_set = test_datagen.flow_from_directory(test_data_dir,\n",
        "#                                            target_size=(224, 224),\n",
        "#                                            batch_size=batch_size,\n",
        "#                                            class_mode='categorical')\n",
        "\n",
        "#print(training_set.class_indices)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s81tULgQMm4g"
      },
      "source": [
        "LEARNING_RATE=0.01\n",
        "MOMENTUM=0.9\n",
        "ALPHA=0.0001\n",
        "BETA=0.75\n",
        "GAMMA=0.1\n",
        "DROPOUT=0.4\n",
        "WEIGHT_DECAY=0.0005\n",
        "LRN2D_NORM=True\n",
        "DATA_FORMAT='channels_last' # Theano:'channels_first' Tensorflow:'channels_last'\n",
        "USE_BN=True\n",
        "\n",
        "IM_WIDTH=224\n",
        "IM_HEIGHT=224\n",
        "EPOCH=200\n",
        "batch_size=32\n",
        "NB_CLASS=39"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_EDE9y5MHFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9770ac3-0507-4851-f244-53e857e47e76"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.3,\n",
        "    rescale=1./255\n",
        ")\n",
        "training_set = datagen.flow_from_directory(\n",
        "  train_data_dir,\n",
        "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "  batch_size=batch_size,\n",
        "  class_mode='categorical', subset='training'\n",
        ")\n",
        "#vaild data\n",
        "test_set = datagen.flow_from_directory(\n",
        "  train_data_dir,\n",
        "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "  batch_size=batch_size,\n",
        "  class_mode='categorical', subset='validation'\n",
        ")\n",
        "#test data\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    featurewise_center=True\n",
        ")\n",
        "test_generator = datagen.flow_from_directory(\n",
        "  test_data_dir,\n",
        "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
        "  batch_size=batch_size,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 30827 images belonging to 39 classes.\n",
            "Found 13189 images belonging to 39 classes.\n",
            "Found 11004 images belonging to 39 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXy138awRw9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1439d6-02e3-426e-86f5-a5ec67f26e30"
      },
      "source": [
        "print(training_set.class_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3, 'Blueberry___healthy': 4, 'Cherry_(including_sour)___Powdery_mildew': 5, 'Cherry_(including_sour)___healthy': 6, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7, 'Corn_(maize)___Common_rust_': 8, 'Corn_(maize)___Northern_Leaf_Blight': 9, 'Corn_(maize)___healthy': 10, 'Grape___Black_rot': 11, 'Grape___Esca_(Black_Measles)': 12, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13, 'Grape___healthy': 14, 'Orange___Haunglongbing_(Citrus_greening)': 15, 'Peach___Bacterial_spot': 16, 'Peach___healthy': 17, 'Pepper,_bell___Bacterial_spot': 18, 'Pepper,_bell___healthy': 19, 'Potato___Early_blight': 20, 'Potato___Late_blight': 21, 'Potato___healthy': 22, 'Raspberry___healthy': 23, 'Soybean___healthy': 24, 'Squash___Powdery_mildew': 25, 'Strawberry___Leaf_scorch': 26, 'Strawberry___healthy': 27, 'Tomato___Bacterial_spot': 28, 'Tomato___Early_blight': 29, 'Tomato___Late_blight': 30, 'Tomato___Leaf_Mold': 31, 'Tomato___Septoria_leaf_spot': 32, 'Tomato___Spider_mites Two-spotted_spider_mite': 33, 'Tomato___Target_Spot': 34, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35, 'Tomato___Tomato_mosaic_virus': 36, 'Tomato___healthy': 37, 'background': 38}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBNl8e5mE6HR"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_c9Fqzu_rRf"
      },
      "source": [
        "#val_batches = tf.data.experimental.cardinality(test_data_dir)\n",
        "#test_dataset = validation_dataset.take(val_batches // 5)\n",
        "#test_data_dir  = validation_dataset.skip(val_batches // 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS3oSKe1_g2C"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "#train_data_dir = train_data_dir.prefetch(buffer_size=AUTOTUNE)\n",
        "#test_data_dir = test_data_dir.prefetch(buffer_size=AUTOTUNE)\n",
        "#test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4xHlkhzUGwy"
      },
      "source": [
        "# # checkpoint\n",
        "# weightpath = \"weights_1.hdf5\"\n",
        "# checkpoint = ModelCheckpoint(weightpath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "# callbacks_list = [checkpoint]\n",
        "#\n",
        "#\n",
        "# #fitting images to CNN\n",
        "# history = classifier.fit_generator(training_set,\n",
        "#                          steps_per_epoch=training_set.samples//batch_size,\n",
        "#                          validation_data=test_set,\n",
        "#                          epochs=50,\n",
        "#                          validation_steps=test_set.samples//batch_size,\n",
        "#                          callbacks=callbacks_list)\n",
        "\n",
        "\n",
        "#fitting images to CNN\n",
        "history = classifier.fit_generator(training_set,\n",
        "                                   steps_per_epoch=training_set.samples//batch_size,\n",
        "                                   validation_data=test_set,\n",
        "                                   epochs=50,\n",
        "                                   validation_steps=test_set.samples//batch_size)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "judM07B2UpKC"
      },
      "source": [
        "#saving model\n",
        "filepath=\"model.hdf5\"\n",
        "classifier.save(filepath)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PZzseCNUxMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9844b06-568d-44de-faa9-725be1c9724e"
      },
      "source": [
        "\n",
        "loss,acc=classifier.evaluate_generator(test_generator,steps=test_set.n/batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 412.15625 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKA_zi6RUyr-"
      },
      "source": [
        "print('Test result:loss:%f,acc:%f'%(loss,acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75wjEVZ-9Yab"
      },
      "source": [
        "Comparing the accuracy and loss by plotting the graph for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68DC4UqXTH4r"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Train and validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXO9rDqtNlDN"
      },
      "source": [
        "convert modÃ¨le to tensorflow js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsR9sMVsJqTE"
      },
      "source": [
        "!pip install tensorflowjs\r\n",
        "!tensorflowjs_converter --input_format keras \"googlenet_flower.h5\" /content/jj"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}